
# mille-feuille

`milleâ€‘feuille` is a thin layer on top of [**BoTorch**](https://botorch.org/) that adds the plumbing you need to run optimisation loops against expensive HPC codesâ€”locally while you prototype, or scaled out on a cluster when the time comes.

> **Status:** early days â€“ very much a work in progress

---

## ğŸ”§ Install

Pip:

```bash
# Development head
pip install git+https://github.com/aidancrilly/mille-feuille.git
```

Or clone repo and install dev environment:

```bash
git clone https://github.com/aidancrilly/mille-feuille.git
cd mille-feuille
pip install -e .[dev]
```

Requires **PythonÂ â‰¥â€¯3.11**. Core dependencies (`botorch`, `gpytorch`, `numpy`, `scipy`, `h5py`, `scikitâ€‘learn` â€¦) are pulled in automatically.

---

## ğŸš€ Quickâ€‘start

```python
import numpy as np

from scipy.stats.qmc import LatinHypercube

from botorch.acquisition import qUpperConfidenceBound

from millefeuille.domain import InputDomain
from millefeuille.state import State
from millefeuille.surrogate import SingleFidelityGPSurrogate
from millefeuille.optimise import suggest_next_locations
from millefeuille.initialise import generate_initial_sample

#Â 1. Problem setup ----------------------------------------------------------
domain = InputDomain(
    dim=2,
    b_low=np.array([-5.0, -5.0]),
    b_up=np.array([5.0, 5.0]),
    steps=np.array([0.0, 0.0])   # both dims continuous
)

# Function to be maximised
def f_optim(x):
    return -np.vecdot(x,x,axis=1)

# 2. Create initial training data -------------------------------------------

# Initial random sampling
nsims = 10
sampler = LatinHypercube(domain.dim)
index = np.arange(nsims,dtype=int)
Xs, _ = generate_initial_sample(domain,sampler,nsims)
Ys = f_optim(Xs)

# 3. Set up mille-feuille state & surrogate ---------------------------------
# Package into millefeuille State
state = State(
	input_domain=domain,
	index=index,
	Xs=Xs,
	Ys=Ys
)

# Create surrogate model based on state
surrogate = SingleFidelityGPSurrogate()
surrogate.init(state)

# 4. Optimiser call ---------------------------------------------------------
# Use botorch acquistion functions
acq_function = qUpperConfidenceBound(surrogate.model,beta=0.5)

X_next = suggest_next_locations(
    batch_size=2,
    state=state,
    surrogate=surrogate,
    acq_function=acq_function
)
print(X_next)    # candidate points in original scale
```

Plug in your own simulator to evaluate `X_next`, update the `State`, and repeat.

---



## ğŸ¤ Relationship to BoTorch

`milleâ€‘feuille` is *additive*: all modelling and acquisition is delegated to BoTorch. What we provide is

- **Thin wrappers** around BoTorch models so you can swap simulators and surrogates without touching the optimiser loop.
- **State and simulator bookkeeping** streamlining the interaction between HPC codes and BO.
- **Job scheduling adapters** so the same simulator class can be adapted to different HPC systems.

When you need full flexibility you can always drop down and call BoTorch directly.

---

## ğŸ› ï¸ Roadmap / work in progress

- **Alternative surrogates** â€“ initial experiments with NN-ensemble based surrogates.
- **Schedulers** â€“ reference Slurm & PBS implementations.
- **Examples** â€“ Show .`Simulator` Classes for open source HPC physics codes.

---

## âœ‰ï¸ Contact

**AidanÂ Crilly** Â· [ac116@ic.ac.uk](mailto\:ac116@ic.ac.uk)

---

Licensed under MIT Â©Â 2025
